{
    "2506.06023": {
        "authors": [
            "Xingchang Huang",
            "Ashish Kumar Singh",
            "Florian Dubost",
            "Cristina Nader Vasconcelos",
            "Sakar Khattar",
            "Liang Shi",
            "Christian Theobalt",
            "Cengiz Oztireli",
            "Gurprit Singh"
        ],
        "title": "Restereo: Diffusion stereo video generation and restoration",
        "abstract": "arXiv:2506.06023v1 Announce Type: new  Abstract: Stereo video generation has been gaining increasing attention with recent advancements in video diffusion models. However, most existing methods focus on generating 3D stereoscopic videos from monocular 2D videos. These approaches typically assume that the input monocular video is of high quality, making the task primarily about inpainting occluded regions in the warped video while preserving disoccluded areas. In this paper, we introduce a new pipeline that not only generates stereo videos but also enhances both left-view and right-view videos consistently with a single model. Our approach achieves this by fine-tuning the model on degraded data for restoration, as well as conditioning the model on warped masks for consistent stereo generation. As a result, our method can be fine-tuned on a relatively small synthetic stereo video datasets and applied to low-quality real-world videos, performing both stereo video generation and restoration. Experiments demonstrate that our method outperforms existing approaches both qualitatively and quantitatively in stereo video generation from low-resolution inputs.",
        "arxiv_id": "2506.06023",
        "ARXIVID": "2506.06023",
        "COMMENT": "Matches criteria 2 closely as it discusses a diffusion model for stereo video generation and restoration, but does not mention multi-task learning or segmentation.",
        "RELEVANCE": 3,
        "NOVELTY": 5
    }
}
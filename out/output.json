{
    "2601.21498": {
        "authors": [
            "Thanh-Nhan Vo",
            "Trong-Thuan Nguyen",
            "Tam V. Nguyen",
            "Minh-Triet Tran"
        ],
        "title": "SimGraph: A Unified Framework for Scene Graph-Based Image Generation and Editing",
        "abstract": "arXiv:2601.21498v1 Announce Type: new  Abstract: Recent advancements in Generative Artificial Intelligence (GenAI) have significantly enhanced the capabilities of both image generation and editing. However, current approaches often treat these tasks separately, leading to inefficiencies and challenges in maintaining spatial consistency and semantic coherence between generated content and edits. Moreover, a major obstacle is the lack of structured control over object relationships and spatial arrangements. Scene graph-based methods, which represent objects and their interrelationships in a structured format, offer a solution by providing greater control over composition and interactions in both image generation and editing. To address this, we introduce SimGraph, a unified framework that integrates scene graph-based image generation and editing, enabling precise control over object interactions, layouts, and spatial coherence. In particular, our framework integrates token-based generation and diffusion-based editing within a single scene graph-driven model, ensuring high-quality and consistent results. Through extensive experiments, we empirically demonstrate that our approach outperforms existing state-of-the-art methods.",
        "arxiv_id": "2601.21498",
        "ARXIVID": "2601.21498",
        "COMMENT": "Matches criteria 1 closely as it proposes a unified framework for image generation and editing using scene graphs, which involves joint generation and segmentation.",
        "RELEVANCE": 5,
        "NOVELTY": 7
    },
    "2601.21592": {
        "authors": [
            "Luwei Tu",
            "Jiawei Wu",
            "Xing Luo",
            "Zhi Jin"
        ],
        "title": "Unifying Heterogeneous Degradations: Uncertainty-Aware Diffusion Bridge Model for All-in-One Image Restoration",
        "abstract": "arXiv:2601.21592v1 Announce Type: new  Abstract: All-in-One Image Restoration (AiOIR) faces the fundamental challenge in reconciling conflicting optimization objectives across heterogeneous degradations. Existing methods are often constrained by coarse-grained control mechanisms or fixed mapping schedules, yielding suboptimal adaptation. To address this, we propose an Uncertainty-Aware Diffusion Bridge Model (UDBM), which innovatively reformulates AiOIR as a stochastic transport problem steered by pixel-wise uncertainty. By introducing a relaxed diffusion bridge formulation which replaces the strict terminal constraint with a relaxed constraint, we model the uncertainty of degradations while theoretically resolving the drift singularity inherent in standard diffusion bridges. Furthermore, we devise a dual modulation strategy: the noise schedule aligns diverse degradations into a shared high-entropy latent space, while the path schedule adaptively regulates the transport trajectory motivated by the viscous dynamics of entropy regularization. By effectively rectifying the transport geometry and dynamics, UDBM achieves state-of-the-art performance across diverse restoration tasks within a single inference step.",
        "arxiv_id": "2601.21592",
        "ARXIVID": "2601.21592",
        "COMMENT": "Does not match any specific criteria closely. It focuses on image restoration using a diffusion model, which is not directly related to the specified criteria.",
        "RELEVANCE": 3,
        "NOVELTY": 6
    }
}
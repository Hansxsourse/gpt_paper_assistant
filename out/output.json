{
    "2507.16718": {
        "authors": [
            "Yiqing Shen",
            "Chenjia Li",
            "Chenxiao Fan",
            "Mathias Unberath"
        ],
        "title": "Temporally-Constrained Video Reasoning Segmentation and Automated Benchmark Construction",
        "abstract": "arXiv:2507.16718v1 Announce Type: new  Abstract: Conventional approaches to video segmentation are confined to predefined object categories and cannot identify out-of-vocabulary objects, let alone objects that are not identified explicitly but only referred to implicitly in complex text queries. This shortcoming limits the utility for video segmentation in complex and variable scenarios, where a closed set of object categories is difficult to define and where users may not know the exact object category that will appear in the video. Such scenarios can arise in operating room video analysis, where different health systems may use different workflows and instrumentation, requiring flexible solutions for video analysis. Reasoning segmentation (RS) now offers promise towards such a solution, enabling natural language text queries as interaction for identifying object to segment. However, existing video RS formulation assume that target objects remain contextually relevant throughout entire video sequences. This assumption is inadequate for real-world scenarios in which objects of interest appear, disappear or change relevance dynamically based on temporal context, such as surgical instruments that become relevant only during specific procedural phases or anatomical structures that gain importance at particular moments during surgery. Our first contribution is the introduction of temporally-constrained video reasoning segmentation, a novel task formulation that requires models to implicitly infer when target objects become contextually relevant based on text queries that incorporate temporal reasoning. Since manual annotation of temporally-constrained video RS datasets would be expensive and limit scalability, our second contribution is an innovative automated benchmark construction method. Finally, we present TCVideoRSBenchmark, a temporally-constrained video RS dataset containing 52 samples using the videos from the MVOR dataset.",
        "arxiv_id": "2507.16718",
        "ARXIVID": "2507.16718",
        "COMMENT": "The paper introduces a novel task formulation for video reasoning segmentation, but it does not involve joint generation and segmentation or multi-task diffusion models.",
        "RELEVANCE": 3,
        "NOVELTY": 7
    },
    "2507.16290": {
        "authors": [
            "Xianze Fang",
            "Jingnan Gao",
            "Zhe Wang",
            "Zhuo Chen",
            "Xingyu Ren",
            "Jiangjing Lyu",
            "Qiaomu Ren",
            "Zhonglei Yang",
            "Xiaokang Yang",
            "Yichao Yan",
            "Chengfei Lyu"
        ],
        "title": "Dens3R: A Foundation Model for 3D Geometry Prediction",
        "abstract": "arXiv:2507.16290v1 Announce Type: new  Abstract: Recent advances in dense 3D reconstruction have led to significant progress, yet achieving accurate unified geometric prediction remains a major challenge. Most existing methods are limited to predicting a single geometry quantity from input images. However, geometric quantities such as depth, surface normals, and point maps are inherently correlated, and estimating them in isolation often fails to ensure consistency, thereby limiting both accuracy and practical applicability. This motivates us to explore a unified framework that explicitly models the structural coupling among different geometric properties to enable joint regression. In this paper, we present Dens3R, a 3D foundation model designed for joint geometric dense prediction and adaptable to a wide range of downstream tasks. Dens3R adopts a two-stage training framework to progressively build a pointmap representation that is both generalizable and intrinsically invariant. Specifically, we design a lightweight shared encoder-decoder backbone and introduce position-interpolated rotary positional encoding to maintain expressive power while enhancing robustness to high-resolution inputs. By integrating image-pair matching features with intrinsic invariance modeling, Dens3R accurately regresses multiple geometric quantities such as surface normals and depth, achieving consistent geometry perception from single-view to multi-view inputs. Additionally, we propose a post-processing pipeline that supports geometrically consistent multi-view inference. Extensive experiments demonstrate the superior performance of Dens3R across various dense 3D prediction tasks and highlight its potential for broader applications.",
        "arxiv_id": "2507.16290",
        "ARXIVID": "2507.16290",
        "COMMENT": "The paper presents a unified framework for joint geometric dense prediction, but it does not involve image generation or segmentation tasks.",
        "RELEVANCE": 3,
        "NOVELTY": 6
    },
    "2507.16429": {
        "authors": [
            "Lin Xi",
            "Yingliang Ma",
            "Cheng Wang",
            "Sandra Howell",
            "Aldo Rinaldi",
            "Kawal S. Rhode"
        ],
        "title": "Robust Noisy Pseudo-label Learning for Semi-supervised Medical Image Segmentation Using Diffusion Model",
        "abstract": "arXiv:2507.16429v1 Announce Type: new  Abstract: Obtaining pixel-level annotations in the medical domain is both expensive and time-consuming, often requiring close collaboration between clinical experts and developers. Semi-supervised medical image segmentation aims to leverage limited annotated data alongside abundant unlabeled data to achieve accurate segmentation. However, existing semi-supervised methods often struggle to structure semantic distributions in the latent space due to noise introduced by pseudo-labels. In this paper, we propose a novel diffusion-based framework for semi-supervised medical image segmentation. Our method introduces a constraint into the latent structure of semantic labels during the denoising diffusion process by enforcing prototype-based contrastive consistency. Rather than explicitly delineating semantic boundaries, the model leverages class prototypes centralized semantic representations in the latent space as anchors. This strategy improves the robustness of dense predictions, particularly in the presence of noisy pseudo-labels. We also introduce a new publicly available benchmark: Multi-Object Segmentation in X-ray Angiography Videos (MOSXAV), which provides detailed, manually annotated segmentation ground truth for multiple anatomical structures in X-ray angiography videos. Extensive experiments on the EndoScapes2023 and MOSXAV datasets demonstrate that our method outperforms state-of-the-art medical image segmentation approaches under the semi-supervised learning setting. This work presents a robust and data-efficient diffusion model that offers enhanced flexibility and strong potential for a wide range of clinical applications.",
        "arxiv_id": "2507.16429",
        "ARXIVID": "2507.16429",
        "COMMENT": "The paper introduces a diffusion-based framework for semi-supervised medical image segmentation, which is not a unified model for generation and segmentation.",
        "RELEVANCE": 3,
        "NOVELTY": 5
    }
}
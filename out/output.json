{
    "2601.23286": {
        "authors": [
            "Hongyang Du",
            "Junjie Ye",
            "Xiaoyan Cong",
            "Runhao Li",
            "Jingcheng Ni",
            "Aman Agarwal",
            "Zeqi Zhou",
            "Zekun Li",
            "Randall Balestriero",
            "Yue Wang"
        ],
        "title": "VideoGPA: Distilling Geometry Priors for 3D-Consistent Video Generation",
        "abstract": "arXiv:2601.23286v1 Announce Type: new  Abstract: While recent video diffusion models (VDMs) produce visually impressive results, they fundamentally struggle to maintain 3D structural consistency, often resulting in object deformation or spatial drift. We hypothesize that these failures arise because standard denoising objectives lack explicit incentives for geometric coherence. To address this, we introduce VideoGPA (Video Geometric Preference Alignment), a data-efficient self-supervised framework that leverages a geometry foundation model to automatically derive dense preference signals that guide VDMs via Direct Preference Optimization (DPO). This approach effectively steers the generative distribution toward inherent 3D consistency without requiring human annotations. VideoGPA significantly enhances temporal stability, physical plausibility, and motion coherence using minimal preference pairs, consistently outperforming state-of-the-art baselines in extensive experiments.",
        "arxiv_id": "2601.23286",
        "ARXIVID": "2601.23286",
        "COMMENT": "",
        "RELEVANCE": 3,
        "NOVELTY": 6
    },
    "2601.22275": {
        "authors": [
            "Cheng Liang",
            "Haoxian Chen",
            "Liang Hou",
            "Qi Fan",
            "Gangshan Wu",
            "Xin Tao",
            "Limin Wang"
        ],
        "title": "VMonarch: Efficient Video Diffusion Transformers with Structured Attention",
        "abstract": "arXiv:2601.22275v1 Announce Type: new  Abstract: The quadratic complexity of the attention mechanism severely limits the context scalability of Video Diffusion Transformers (DiTs). We find that the highly sparse spatio-temporal attention patterns exhibited in Video DiTs can be naturally represented by the Monarch matrix. It is a class of structured matrices with flexible sparsity, enabling sub-quadratic attention via an alternating minimization algorithm. Accordingly, we propose VMonarch, a novel attention mechanism for Video DiTs that enables efficient computation over the dynamic sparse patterns with structured Monarch matrices. First, we adapt spatio-temporal Monarch factorization to explicitly capture the intra-frame and inter-frame correlations of the video data. Second, we introduce a recomputation strategy to mitigate artifacts arising from instabilities during alternating minimization of Monarch matrices. Third, we propose a novel online entropy algorithm fused into FlashAttention, enabling fast Monarch matrix updates for long sequences. Extensive experiments demonstrate that VMonarch achieves comparable or superior generation quality to full attention on VBench after minimal tuning. It overcomes the attention bottleneck in Video DiTs, reduces attention FLOPs by a factor of 17.5, and achieves a speedup of over 5x in attention computation for long videos, surpassing state-of-the-art sparse attention methods at 90% sparsity.",
        "arxiv_id": "2601.22275",
        "ARXIVID": "2601.22275",
        "COMMENT": "",
        "RELEVANCE": 3,
        "NOVELTY": 5
    }
}
{
    "2601.11522": {
        "authors": [
            "Ruiheng Zhang",
            "Jingfeng Yao",
            "Huangxuan Zhao",
            "Hao Yan",
            "Xiao He",
            "Lei Chen",
            "Zhou Wei",
            "Yong Luo",
            "Zengmao Wang",
            "Lefei Zhang",
            "Dacheng Tao",
            "Bo Du"
        ],
        "title": "UniX: Unifying Autoregression and Diffusion for Chest X-Ray Understanding and Generation",
        "abstract": "arXiv:2601.11522v1 Announce Type: new  Abstract: Despite recent progress, medical foundation models still struggle to unify visual understanding and generation, as these tasks have inherently conflicting goals: semantic abstraction versus pixel-level reconstruction. Existing approaches, typically based on parameter-shared autoregressive architectures, frequently lead to compromised performance in one or both tasks. To address this, we present UniX, a next-generation unified medical foundation model for chest X-ray understanding and generation. UniX decouples the two tasks into an autoregressive branch for understanding and a diffusion branch for high-fidelity generation. Crucially, a cross-modal self-attention mechanism is introduced to dynamically guide the generation process with understanding features. Coupled with a rigorous data cleaning pipeline and a multi-stage training strategy, this architecture enables synergistic collaboration between tasks while leveraging the strengths of diffusion models for superior generation. On two representative benchmarks, UniX achieves a 46.1% improvement in understanding performance (Micro-F1) and a 24.2% gain in generation quality (FD-RadDino), using only a quarter of the parameters of LLM-CXR. By achieving performance on par with task-specific models, our work establishes a scalable paradigm for synergistic medical image understanding and generation. Codes and models are available at https://github.com/ZrH42/UniX.",
        "arxiv_id": "2601.11522",
        "ARXIVID": "2601.11522",
        "COMMENT": "Matches criterion 2: Unified Diffusion Models for multiple vision tasks",
        "RELEVANCE": 5,
        "NOVELTY": 7
    },
    "2601.11194": {
        "authors": [
            "Boyi Pang",
            "Savva Ignatyev",
            "Vladimir Ippolitov",
            "Ramil Khafizov",
            "Yurii Melnik",
            "Oleg Voynov",
            "Maksim Nakhodnov",
            "Aibek Alanov",
            "Xiaopeng Fan",
            "Peter Wonka",
            "Evgeny Burnaev"
        ],
        "title": "ATATA: One Algorithm to Align Them All",
        "abstract": "arXiv:2601.11194v1 Announce Type: new  Abstract: We suggest a new multi-modal algorithm for joint inference of paired structurally aligned samples with Rectified Flow models. While some existing methods propose a codependent generation process, they do not view the problem of joint generation from a structural alignment perspective. Recent work uses Score Distillation Sampling to generate aligned 3D models, but SDS is known to be time-consuming, prone to mode collapse, and often provides cartoonish results. By contrast, our suggested approach relies on the joint transport of a segment in the sample space, yielding faster computation at inference time. Our approach can be built on top of an arbitrary Rectified Flow model operating on the structured latent space. We show the applicability of our method to the domains of image, video, and 3D shape generation using state-of-the-art baselines and evaluate it against both editing-based and joint inference-based competing approaches. We demonstrate a high degree of structural alignment for the sample pairs obtained with our method and a high visual quality of the samples. Our method improves the state-of-the-art for image and video generation pipelines. For 3D generation, it is able to show comparable quality while working orders of magnitude faster.",
        "arxiv_id": "2601.11194",
        "ARXIVID": "2601.11194",
        "COMMENT": "Does not match any specific criteria",
        "RELEVANCE": 3,
        "NOVELTY": 6
    }
}
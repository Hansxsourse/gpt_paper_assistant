{
    "2512.17504": {
        "authors": [
            "Hoiyeong Jin",
            "Hyojin Jang",
            "Jeongho Kim",
            "Junha Hyung",
            "Kinam Kim",
            "Dongjin Kim",
            "Huijin Choi",
            "Hyeonji Kim",
            "Jaegul Choo"
        ],
        "title": "InsertAnywhere: Bridging 4D Scene Geometry and Diffusion Models for Realistic Video Object Insertion",
        "abstract": "arXiv:2512.17504v1 Announce Type: new  Abstract: Recent advances in diffusion-based video generation have opened new possibilities for controllable video editing, yet realistic video object insertion (VOI) remains challenging due to limited 4D scene understanding and inadequate handling of occlusion and lighting effects. We present InsertAnywhere, a new VOI framework that achieves geometrically consistent object placement and appearance-faithful video synthesis. Our method begins with a 4D aware mask generation module that reconstructs the scene geometry and propagates user specified object placement across frames while maintaining temporal coherence and occlusion consistency. Building upon this spatial foundation, we extend a diffusion based video generation model to jointly synthesize the inserted object and its surrounding local variations such as illumination and shading. To enable supervised training, we introduce ROSE++, an illumination aware synthetic dataset constructed by transforming the ROSE object removal dataset into triplets of object removed video, object present video, and a VLM generated reference image. Through extensive experiments, we demonstrate that our framework produces geometrically plausible and visually coherent object insertions across diverse real world scenarios, significantly outperforming existing research and commercial models.",
        "arxiv_id": "2512.17504",
        "ARXIVID": "2512.17504",
        "COMMENT": "The paper does not match any specific criteria closely.",
        "RELEVANCE": 3,
        "NOVELTY": 6
    },
    "2512.17323": {
        "authors": [
            "Jiyun Kong",
            "Jun-Hyuk Kim",
            "Jong-Seok Lee"
        ],
        "title": "DESSERT: Diffusion-based Event-driven Single-frame Synthesis via Residual Training",
        "abstract": "arXiv:2512.17323v1 Announce Type: new  Abstract: Video frame prediction extrapolates future frames from previous frames, but suffers from prediction errors in dynamic scenes due to the lack of information about the next frame. Event cameras address this limitation by capturing per-pixel brightness changes asynchronously with high temporal resolution. Prior research on event-based video frame prediction has leveraged motion information from event data, often by predicting event-based optical flow and reconstructing frames via pixel warping. However, such approaches introduce holes and blurring when pixel displacement is inaccurate. To overcome this limitation, we propose DESSERT, a diffusion-based event-driven single-frame synthesis framework via residual training. Leveraging a pre-trained Stable Diffusion model, our method is trained on inter-frame residuals to ensure temporal consistency. The training pipeline consists of two stages: (1) an Event-to-Residual Alignment Variational Autoencoder (ER-VAE) that aligns the event frame between anchor and target frames with the corresponding residual, and (2) a diffusion model that denoises the residual latent conditioned on event data. Furthermore, we introduce Diverse-Length Temporal (DLT) augmentation, which improves robustness by training on frame segments of varying temporal lengths. Experimental results demonstrate that our method outperforms existing event-based reconstruction, image-based video frame prediction, event-based video frame prediction, and one-sided event-based video frame interpolation methods, producing sharper and more temporally consistent frame synthesis.",
        "arxiv_id": "2512.17323",
        "ARXIVID": "2512.17323",
        "COMMENT": "The paper does not match any specific criteria closely.",
        "RELEVANCE": 3,
        "NOVELTY": 5
    }
}
{
    "2601.00328": {
        "authors": [
            "Yingzhi Tang",
            "Qijian Zhang",
            "Junhui Hou"
        ],
        "title": "Joint Geometry-Appearance Human Reconstruction in a Unified Latent Space via Bridge Diffusion",
        "abstract": "arXiv:2601.00328v1 Announce Type: new  Abstract: Achieving consistent and high-fidelity geometry and appearance reconstruction of 3D digital humans from a single RGB image is inherently a challenging task. Existing studies typically resort to decoupled pipelines for geometry estimation and appearance synthesis, often hindering unified reconstruction and causing inconsistencies. This paper introduces \\textbf{JGA-LBD}, a novel framework that unifies the modeling of geometry and appearance into a joint latent representation and formulates the generation process as bridge diffusion. Observing that directly integrating heterogeneous input conditions (e.g., depth maps, SMPL models) leads to substantial training difficulties, we unify all conditions into the 3D Gaussian representations, which can be further compressed into a unified latent space through a shared sparse variational autoencoder (VAE). Subsequently, the specialized form of bridge diffusion enables to start with a partial observation of the target latent code and solely focuses on inferring the missing components. Finally, a dedicated decoding module extracts the complete 3D human geometric structure and renders novel views from the inferred latent representation. Experiments demonstrate that JGA-LBD outperforms current state-of-the-art approaches in terms of both geometry fidelity and appearance quality, including challenging in-the-wild scenarios. Our code will be made publicly available at https://github.com/haiantyz/JGA-LBD.",
        "arxiv_id": "2601.00328",
        "ARXIVID": "2601.00328",
        "COMMENT": "The paper introduces a unified framework for joint geometry and appearance reconstruction using bridge diffusion, which aligns with the unified diffusion models criterion.",
        "RELEVANCE": 5,
        "NOVELTY": 7
    },
    "2601.00090": {
        "authors": [
            "Anne Harrington",
            "A. Sophia Koepke",
            "Shyamgopal Karthik",
            "Trevor Darrell",
            "Alexei A. Efros"
        ],
        "title": "It's Never Too Late: Noise Optimization for Collapse Recovery in Trained Diffusion Models",
        "abstract": "arXiv:2601.00090v1 Announce Type: new  Abstract: Contemporary text-to-image models exhibit a surprising degree of mode collapse, as can be seen when sampling several images given the same text prompt. While previous work has attempted to address this issue by steering the model using guidance mechanisms, or by generating a large pool of candidates and refining them, in this work we take a different direction and aim for diversity in generations via noise optimization. Specifically, we show that a simple noise optimization objective can mitigate mode collapse while preserving the fidelity of the base model. We also analyze the frequency characteristics of the noise and show that alternative noise initializations with different frequency profiles can improve both optimization and search. Our experiments demonstrate that noise optimization yields superior results in terms of generation quality and variety.",
        "arxiv_id": "2601.00090",
        "ARXIVID": "2601.00090",
        "COMMENT": "The paper focuses on noise optimization for improving diversity in text-to-image diffusion models, which does not match any specific criteria.",
        "RELEVANCE": 3,
        "NOVELTY": 5
    }
}